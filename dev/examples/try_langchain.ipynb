{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-11T09:50:32.093188Z",
     "start_time": "2024-03-11T09:50:32.088518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Example 1 - how to use langchain to create a chatbot"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ea65dcb7cd626f9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from langchain_community.chat_models import ChatYandexGPT\n",
    "# from langchain_community.chat_models import GigaChat\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough, RunnableMap\n",
    "\n",
    "common_settings = {\n",
    "    # \"http_client\": proxied_http_client,\n",
    "    \"request_timeout\": 60,\n",
    "    \"max_retries\": 3,\n",
    "    \"max_tokens\": 1024,\n",
    "}\n",
    "\n",
    "basic_llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", **common_settings)\n",
    "static_llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", **common_settings, temperature=0.0)\n",
    "mid_llm = ChatOpenAI(model=\"gpt-4-0125-preview\", **common_settings)\n",
    "smart_llm = ChatOpenAI(model=\"gpt-4\", **common_settings)\n",
    "vision_llm = ChatOpenAI(model=\"gpt-4-vision-preview\", **common_settings)\n",
    "\n",
    "anthropic_settings = {\n",
    "    # \"http_client\": proxied_http_client,\n",
    "    \"max_retries\": 3,\n",
    "}\n",
    "anthropic_mid_llm = ChatAnthropic(model=\"claude-3-sonnet-20240229\", client_kwargs=anthropic_settings)\n",
    "anthropic_smart_llm = ChatAnthropic(model=\"claude-3-opus-20240229\", client_kwargs=anthropic_settings)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6de0a0d7c6cc64d1",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Example 2 - minimal chat completion"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e24ac25e50af2b2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def simple_chat(message, kind=\"openai\"):\n",
    "    llm = None\n",
    "    if kind == \"openai\":\n",
    "        llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "    elif kind == \"anthropic\":\n",
    "        llm = ChatAnthropic(model=\"claude-3-sonnet-20240229\")\n",
    "    \n",
    "    res = llm.invoke(message)\n",
    "    \n",
    "    return res.content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T09:50:38.173446Z",
     "start_time": "2024-03-11T09:50:37.205132Z"
    }
   },
   "id": "5b2b3a6e7b8fa3be",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "text = \"Once upon a time, there was a little\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T09:55:04.190532Z",
     "start_time": "2024-03-11T09:55:04.188172Z"
    }
   },
   "id": "58d4e0ded259fa70",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " girl named Lily who lived in a small village at the edge of the forest. Lily was known for her kind heart and adventurous spirit. She loved exploring the woods and discovering new things every day.\n",
      "\n",
      "One day, while wandering through the forest, Lily stumbled upon a hidden meadow filled with the most beautiful flowers she had ever seen. As she walked through the meadow, she noticed a tiny fairy fluttering around her, sprinkling sparkling dust on the flowers.\n",
      "\n",
      "The fairy introduced herself as Rosalind and told Lily that she was the guardian of the meadow. She explained that the flowers in the meadow had magical properties and could grant wishes to those who were pure of heart.\n",
      "\n",
      "Excited by the prospect of making a wish, Lily thought long and hard about what she wanted most in the world. After much deliberation, she closed her eyes and made her wish with all her heart.\n",
      "\n",
      "To her amazement, the flowers began to glow and shimmer, and a soft, warm light surrounded her. When she opened her eyes, she found herself standing in her own bedroom, surrounded by her family and friends, who were all smiling and cheering for her.\n",
      "\n",
      "Lily realized that her wish had come true, and she was filled with joy and gratitude. From that day on, she never forgot the magical meadow and the kind fairy who had granted her wish.\n",
      "\n",
      "And so, Lily lived happily ever after, knowing that sometimes, dreams really do come true.\n"
     ]
    }
   ],
   "source": [
    "res = simple_chat(text, kind=\"openai\")\n",
    "print(res)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T09:55:17.160729Z",
     "start_time": "2024-03-11T09:55:09.781067Z"
    }
   },
   "id": "5f9287c022c677d3",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Example 3 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28768b9b99c42888"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "role_message = \"\"\"\n",
    "You are an AI designed to process transcribed conversations from a retail store setting. Perform the following tasks:\n",
    "1. Summarize the Conversation: Generate a concise summary highlighting the main topics, requests, or issues mentioned.\n",
    "2. Identify Presence of a Customer: Determine if the interaction involves a customer and store staff, as opposed to solely between staff members. Your analysis should conclude with a Boolean value indicating the presence (true) or absence (false) of a customer.\n",
    "3. Calculate Customer Conversation Percentage: Estimate the percentage of the conversation that is directly related to interactions with the customer.\n",
    "Return the results as a JSON dictionary with keys 'summary' for the conversation summary and 'is_customer_present' for the Boolean customer presence indicator.\n",
    "\"\"\"\n",
    "\n",
    "example_input_1 = \"\"\"\n",
    "Speaker_1: \"Did you notice the new shipment of winter jackets?\"\n",
    "Speaker_2: \"Yes, I stocked them yesterday. They're really nice.\"\n",
    "Speaker_1: \"We should rearrange the display to feature them prominently.\"\n",
    "\"\"\"\n",
    "\n",
    "example_output_1 = \"\"\"{{\n",
    "    \"summary\": \"Two salespeople discuss the new shipment of winter jackets and consider rearranging the display to highlight them.\",\n",
    "    \"is_customer_present\": false,\n",
    "    \"customer_conversation_percentage\": 0\n",
    "}}\"\"\"\n",
    "\n",
    "example_input_2 = \"\"\"\n",
    "Speaker_1: \"Can you help me find the sports section?\"\n",
    "Speaker_2: \"Certainly! It's right this way, on the second floor.\"\n",
    "Speaker_1: \"Thank you. Also, do you have any running shoes on sale?\"\n",
    "Speaker_2: \"Yes, we have a few models on discount this week. I can show you those as well.\"\n",
    "Speaker_3: \"Make sure to restock the running shoes after showing them.\"\n",
    "\"\"\"\n",
    "\n",
    "example_output_2 = \"\"\"{{\n",
    "    \"summary\": \"A customer asks for directions to the sports section and inquires about running shoes on sale. The salesperson assists and mentions discounted models.\",\n",
    "    \"is_customer_present\": true,\n",
    "    \"customer_conversation_percentage\": 80\n",
    "}}\"\"\"\n",
    "\n",
    "human_template = \"{formatted_text}\"\n",
    "\n",
    "messages = [\n",
    "    (\"system\", role_message),\n",
    "    (\"human\", example_input_1),\n",
    "    (\"ai\", example_output_1),\n",
    "    (\"human\", example_input_2),\n",
    "    (\"ai\", example_output_2),\n",
    "    (\"human\", human_template)\n",
    "]\n",
    "\n",
    "messages = [(tag, trim_extra_whitespace(m)) for tag, m in messages]\n",
    "\n",
    "full_prompt = ChatPromptTemplate.from_messages(messages)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a21068530117e9f0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Example 4 - how to chain actons and build apps"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cab558302c810871"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "76e571bef9870cf5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Example 5 - what is the core idea and benefit of langchain?\n",
    "\n",
    "What does it mean to 'chain'? "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f81a00fb70fc0fd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cb5580c204303b02",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "chain_create_taxonomy = (\n",
    "    ChatPromptTemplate.from_messages([trim_extra_whitespace(prompt_create_taxonomy)]) | mid_llm | StrOutputParser()\n",
    ")\n",
    "chain_convert_taxonomy_to_questions = (\n",
    "    ChatPromptTemplate.from_messages([trim_extra_whitespace(prompt_convert_taxonomy_to_questions)])\n",
    "    | basic_llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "chain_fill_taxonomy = RunnableLambda(custom_vision_template) | vision_llm\n",
    "\n",
    "\n",
    "chain_create_from_scratch = (\n",
    "    RunnablePassthrough.assign(taxonomy=chain_create_taxonomy)\n",
    "    | RunnablePassthrough.assign(taxonomy_questions=chain_convert_taxonomy_to_questions)\n",
    "    | RunnablePassthrough.assign(taxonomy_answer=chain_fill_taxonomy)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9b8703912b64f8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# step 1: get a list of relevant tags\n",
    "def get_tags_for_message():\n",
    "    # go to database\n",
    "    tags = []\n",
    "    return tags\n",
    "\n",
    "# step 2:invoke llm\n",
    "chain_create_from_scratch.invoke()\n",
    "\n",
    "# step 3: add new tags and new item to database"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d2dd63ce833c217",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_tags\n",
    "\n",
    "RunnableLambda(\n",
    "    \n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db7fb5bf38f10924",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How to enable langsmith"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a68e81c9b2874429"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Langchain api key\n",
    "# langchain project\n",
    "# LANGCHAIN_API_KEY\n",
    "# LANGCHAIN_PROJECT\n",
    "# LANGCHAIN_TRACING_V2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82c0ddf443060404",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def go_to_database():\n",
    "    return \"I'm going to the database\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d054673cc4626417",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
